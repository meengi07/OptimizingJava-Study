# Chapter3. 하드웨어와 운영체제

하드웨어는 **무어의 법칙**(대량 생산한 칩의 트랜지스터 수는 약 18개월마다 2배씩 증가한다.) 의 가설대로 발전해왔지만 최근 수십 년 동안 가설은 사망했고, 자바는 컴퓨팅 파워가 향상됨에 따라 혜택을 많이 받았다. 하지만 성능을 고민한다면 가용 리소스를 최대한 활용할 수 있도록 자바 플랫폼의 근간 원리와 기술을 잘 알고 있어야 한다.

# 1. 최신 하드웨어 소개

보통 하드웨어 아키텍처 수업은 간단하고 고전적인 하드웨어 내용을 강의하는 경우가 허다하다. 하드웨어를 레지스터 기반으로 산술,로직,로드,스토어 연산을 수행하는 지극히 뻔한 머신으로 본다. 하지만 인텔 x86/x64 아키텍처 이후 많은 변화를 거쳐 고급 기능들이 핵심부를 형성하고 있다.

# 2. 메모리

무어의 법칙에 따라 개수가 증가한 트랜지스터는 클록 속도를 높이는데 쓰였지만 클록 속도가 증가하니 증가한만큼 데이터도 빨리 움직여야하는데, 프로세서 코어의 데이터 수요를 메인 메모리가 맞추기 어려워졌다.

![스크린샷 2024-01-07 오후 1.30.00.png](./images/스크린샷 2024-01-07 오후 1.30.00.png)

## 2.1 메모리 캐시

CPU캐시는 CPU에 있는 메모리 영역으로 레지스터보다는 느리지만 메인 메모리보다는 훨씬 빠르다. 자주 액세스 하는 메모리 위치는 CPU가 메인 메모리를 재참조하지 않게 사본을 떠서 CPU 캐시에 보관하는 것이다.

CPU에는 액세스 빈도가 높은 캐시일수록 프로세서 코어와 더 가까이 위치하는 식으로 여러 캐시 계층이 있다. CPU와 가장 가까운 캐시가 L1, 그 다음 L2,,, 이런식이며 일반적으로 각 실행 코어에 전용 프라이빗 캐시 L1,L2를 두고, 일부 또는 전체 코어가 공유하는 L3캐시를 둔다.

![스크린샷 2024-01-07 오후 1.33.30.png](./images/스크린샷 2024-01-07 오후 1.33.30.png)

클록 속도와 액세스 시간 차이 때문에 최신 CPU는 더 많은 예산을 캐시에 투자한다. CPU 코어마다 전용 L1, L2 캐시가 있고 모든 코어가 공유하는 L3 캐시가 있으며, 메인 메모리는 노스브리지(Northbridge) 컴포넌트를 거쳐 액세스하고 이 버스를 관통함으로써 메인 메모리 액세스 시간이 확 줄어든다.

![스크린샷 2024-01-07 오후 1.36.58.png](./images/스크린샷 2024-01-07 오후 1.36.58.png)

캐시 아키텍처를 추가해서 프로세서 처리율은 현저히 개선됐지만, 메모리에 있는 데이터를 어떻게 캐시로 가져오고 캐시한 데이터를 어떻게 메모리에 다시 써야 할지에 대한 문제가 있었고, **캐시 일괄성 프로토콜(cache consistency protocol)**이라는 방법으로 해결한다.

프로세서의 가장 저수준에서 MESI(및 그 변종 variants) 라는 프로토콜이 있는데 캐시 라인(보통 64바이트) 상태를 네가지로 정의한다.

- Modified 수정 : 데이터가 수정된 상태
- Exclusive 배타 : 이 캐시에만 존재하고 메인 메모리 내용과 동일한 상태
- Shared 공유 : 둘 이상의 캐시에 데이터가 들어 있고 메모리 내용과 동일한 상태
- Invalid 무효 : 다른 프로세스가 데이터를 수정하여 무효한 상태

요점은 멀티 프로세서가 동시에 공유 상태에 있을 수 있다는 점이다. 하지만 어느 한 프로세서가 배타나 수정 상태로 바뀌면 다른 프로세서는 모두 강제로 무효 상태가 된다. 이 프로토콜에서는 프로세서가 상태를 바꾸겠다는 의사를 브로드캐스팅한다. 공유 메모리버스를 통해 전기 신호를 보내면 다른 프로세서가 이를 알아차린다.

처음 프로세서가 나왔을 땐 매번 캐시 연산 결과를 바로 메모리에 기록(동시 기록 write through)했다. 이것은 메모리 대역폭이 너무 많이 소모되어 효율이 낮아 거의 안쓰며, 나중에 후기록(write back)방식을 채택해 캐시 블록을 교체해도 프로세서가 변경된 캐시 블록만 기록(dirty)하므로 메인 메모리로 돌아가는 트래픽이 떨어진다.

캐시 덕분에 빠르게 메모리에서 쓰고 읽을 수 있다. 메모리 대욕폭 측면에서 그 효과를 나타낼 수 있는데, 이론적으로 가능한 **최대 전송률**(burst rate)은 인자에 따라 달라진다.

- 메모리 클록 주파수
- 메모리 버스 폭(보통64비트)
- 인터페이스 개수(요즘은 대부분2개)

자바 성능을 논할 때는 객체 할당률에 대한 애플리케이션 민감도가 아주 중요하다.

# 3. 최신 프로세서의 특성

메모리 캐시는 점점 증가한 트랜지스터를 가장 확실하게 활용하는 분야지만, 다른 기술도 등장했다.

## 3.1 변환 색인 버퍼(TLB, Translation Lookaside Buffer)

여러 캐시에서 아주 요긴하게 쓰이는 장치로 가상 메모리 주소를 물리 메모리 주소로 매핑하는 페이지 테이블의 캐시 역할을 수행하고, 덕분에 가상 주소를 참조해 물리 주소에 액세스하는 빈번한 작업 속도가 매우 빨라진다.

## 3.2 분기 예측과 추측 실행

분기 예측 (branch prediction)은 최신 프로세서의 고급 기법 중 하나로, 프로세서가 조건 분기하는 기준값을 평가하느라 대기하는 현상을 방지합니다. 최신 프로세서는 다단계 명령 파이프라인을 이용해 CPU 1사이클도 여러 개별 단계로 나누어 실행하므로 여러 명령이 동시 실행 중일 수도 있다.

이런 모델은 조건문을 다 평가하기 전에 분기 이후 다음 명령을 알 수 없다. 그 결과 분기문 뒤에 나오는 다단계 파이프라인을 비우는 동안 프로세서는 여러 사이클동안 멈춘다. 이런 일이 없도록 프로세서는 트랜지스터를 아낌없이 활용해 가장 발생 가능성이 큰 브랜치를 미리 결정하는 **휴리스틱**(문제 해결이나 결정을 위해 사용되는 근사적이고 경험적인 방법이나 규칙을 의미한다.)을 형성한다. 추측이 일치한다면 CPU는 다음 작업을 진행하고 틀리면 실행한 명령을 모두 폐기한 후 파이프라인을 비우는 대가(파이프라인을 비우는 동안 프로세서는 멈춘다.)를 치룬다.

## 3.3 하드웨어 메모리 모델

어떻게 하면 서로 다른 여러 CPU가 일관되게 동일한 메모리 주소를 액세스할 수 있을까? 멀티코어 시스템에서 메모리에 관한 가장 근본적인 질문이다. 해답은 하드웨어 마다 다르지만, JIT컴파일러인 javac와 CPU는 일반적으로 코드 실행 순서를 바꿀 수 있다. 물론 코드 실행 순서를 바꿔도 현재 스레드가 바라보는 결과는 영향이 없다는 전제가 필요하다.

JMM은 프로세서 타입별로 상이한 메모리 액세스 일관성을 고려하여 명시적으로 약한 모델로 설계됐다. 따라서 멀티스레드 코드가 제대로 작동하게 하려면 락과 volatile을 정확히 알고 사용해야 한다.

최근 소프트웨어 개발자들은 더 나은 성능을 얻기 위해 하드웨어 작동 원리를 깊이 이해하려고 노력한다. 마틴 톰슨등의 사람들은 이런 움직임을 기계 공감이라고 표현하며 특히 저지연, 고성능을 필요로하는 분야에 많이 적용 됐다. 최근 락-프리 알고리즘 및 자료 구조 관련 연구 결과에도 나온다.

## 3.4 운영체제

OS의 주 임무는 여러 실행 프로세스가 공유하는 리소스 액세스를 관장하는 일이다. 모든 리소스는 한정돼 있고 프로세스는 저마다 리소스를 더 차지하려고 덤벼들기 때문에 리소스 양을 보고 골고루 나누어 줄 중앙 시스템이 있어야 한다. 한정된 리소스 중에도 메모리와 CPU 시간은 가장 중요하다.

메모리 관리 유닛(MMU, memory management unit)을 통한 가상 주소 방식과 페이지 테이블은 메모리 액세스 제어의 핵심으로서, 한 프로세스가 소유한 메모리 영역을 다른 프로세스가 함부로 훼손하지 못하도록 한다.

TLB는 물리 메모리 주소 룩업 시간을 줄이는 하드웨어 기능이다. 아무래도 버퍼를 사용하면 소프트웨어가 메모리에 액세스하는 성능이 향상되지만, MMU는 개발자가 세부를 파악해서 직접 손대기엔 너무 저수준 영역이므로 대신 OS 액세스 스케줄러를 자세히 살펴봐야 한다. CPU 액세스를 제어하는 OS 액세스 스케줄러는 유저 입장에서 훨씬 시각적인 OS 커널 요소다.

### 3.4.1 스케줄러

프로세스 스케줄러는 CPU 액세스를 통제하며, 실행 큐를 이용한다. 스케줄러는 인터럽트에 응답하고 CPU 코어 액세스를 관리한다.

자바 명세서에는 이론적으로 자바 스레드가 굳이 OS 스레드와 일치할 필요 없는 스레딩 모델(그린 스레드)을 허용한다고 하지만, 실제론 이런 방식이 유용하지 않다는 사실이 밝혀져 주류 운영 환경에서는 배제됐다.

![자바 스레드의 수명주기](./스크린샷 2024-01-07 오후 8.22.14.png)

자바 스레드의 수명주기

위 그림의 OS 스케줄러는 스레드를 시스템 단일 코어로 분주히 나른다. 스케줄러는 할당 시간 끝 무렵에 실행 큐로 되돌려서 큐의 맨 앞으로 가 다시 실행될 때까지 대기시킨다. 스레드가 자신이 할당받은 시간을 자발적으로 포기하려면 `sleep()` 메서드로 잠들 시간을 정하거나 `wait()` 메서드로 대기 조건을 명시한다. 스레드는 I/O 또는 소프트웨어 락에 걸려 블로킹될 수 있다.

OS는 특성상 CPU에서 코드가 실행되지 않는 시간을 유발한다. 쉽게 간과하기 쉬운 OS의 특징이다. 자신의 할당 시간을 다 쓴 프로세스는 실행 큐 맨 앞으로 갈 때까지 CPU로 복귀하지 않는다. CPU가 아껴 써야 할 리소스임을 감안하면 코드가 정작 실행되는 시간보다 기다리는 시간이 더 많다는 뜻이다.

실제로 관측한 프로세스에서 나온 통계치는 시스템에 있는 다른 프로세스의 동작에도 영향을 받는다. 이런 지터(jitter)와 스케줄링 오버헤드는 측정 결과에 노이즈를 끼게 만드는 주요 요인이다. 스케줄러의 움직임을 확인하는 가장 쉬운 방법은 OS가 스케줄링 과정에서 발생시킨 오버헤드를 관측하는 것이다.

### 3.4.2 시간 문제

POSIX(portable operating system interface 이식 가능 운영체제 인터페이스)같은 업계 표준이 있어도 OS는 저마다 다르게 작동한다. 예로 `os::javaTimeMillis()` 함수는 호스트 OS가 제공하는 기능에 의존하는 함수라 네이티브 메서드로 구현한다.

### 3.4.3 컨텍스트 교환

컨텍스트 스위치(context switch)은 OS 스케줄러가 현재 실행 중인 스레드/태스크를 없애고 대기 중인 다른 스레드/태스크로 대체하는 프로세스다. 스레드 실행 명령과 스택 상태를 교체하는 모든 일에 연관되어 있다. 유저 스레드 사이에 발생하든, 유저 모드에서 커널 모드로 바뀌면서 (모드 교환 mode switch) 일어나든 컨텍스트 교환은 비싼 작업이다.

유저 스레드가 타임 슬라이스(time slice: 다중 작업 환경에서 CPU의 시간을 분할해서 각 프로세스마다 일정 시간을 할당하는 기법)도중 커널 모드로 바꾸어 기능을 실행해야 할 때가 있다. 하지만 유저 공간에 있는 코드가 액세스하는 메모리 영역은 커널 코드와 거의 공유할 부분이 없기 때문에 모드가 바뀌면 명령어와 다른 캐시를 어쩔 수 없이 강제로 비워야 한다. 커널 모드로 컨텍스트가 교환되면 TLB(3.1 변환 색인 버퍼)를 비롯한 다른 캐시까지 무효화 된다. 시스템 콜 반환 시 다시 채워야 하므로 커널 모드 교환의 여파는 유저 공간으로 다시 제어권이 넘어간 후에도 당분간 이어진다.

리눅스는 이를 최대한 만회하려고 가상 동적 공유 객체(vDSO, virtual Dynamically Shared object)라는 장치를 제공하여 커널 프리빌리지(특권 kernel privileges)이 필요 없는 시스템 콜의 속도를 높이려고 쓰는 유저 공간의 메모리 영역이다. 커널 모드로 컨텍스트를 교환하지 않으면 그만큼 속도가 빠르다.

`gettimeofday()` 는 유닉스에서 자주 쓰이는 시스템 콜로 OS가 인지한 벽시계 시간(wallclock time)을 반환한다. 백그라운드로 커널 자료 구조를 읽어 시스템 클록 시간을 얻는다. 사이드 이펙트를 일으키지 않으므로 실제 프리빌리지드 액세스는 필요 없다. 이 자료구조를 vDSO로 유저 프로세스의 주소 공간에 매핑시킬 수 있다면 커널 모드로 바꿀 필요가 없다.

타이밍 자료를 빈번하게 액세스하는 자바 애플리케이션에서는 이런식으로 성능을 끌어올릴 수 있다.

## 3.5 단순 시스템 모델

시스템 모델은 근본 서브시스템의 OS 측정값으로 나타낼 수 있고 표준 유닉스 명령줄 툴의 출력 결과와 직접 연관 지을 수도 있다. 시스템 모델의 근본은 유닉스 계열 OS에서 작동하는 자바 애플리케이션의 단순한 개념으로 기본 컴포넌트로 구성된다.

- 애플리케이션이 실행되는 하드웨어와 OS
- 애플리케이션이 실행되는 JVM/컨테이너
- 애플리케이션 코드 자체
- 애플리케이션이 호출하는 외부 시스템
- 애플리케이션으로 유압되는 트래픽

  ![스크린샷 2024-01-07 오후 9.31.13.png](./images/스크린샷 2024-01-07 오후 9.31.13.png)


## 3.6 기본 감지 전략

애플리케이션이 잘 돌아간다는건 CPU사용량, 메모리, 네트워크, I/O 대역폭 등 시스템 리소스를 효율적으로 잘 이용하고 있다는 뜻이다. 성능 진단의 첫 단추는 어느 리소스가 한계에 다다랐는지 밝히는 일로 부족한 리소스가 뭔지 몰라서는 성능 지표를 제대로 튜닝할 수 없다.

### 3.6.1 CPU 사용률

CPU 사용률은 애플리케잇녀 성능을 나타내는 핵심 지표다. CPU 사이클은 애플리케이션이 가장 갈증을 느끼는 리소스라서 CPU의 효율적 사용은 성능 향상의 지름길이다. 또 부하가 집중되는 도중에는 사용률이 가능한 100% 에 가까워야 한다.

기본 툴 두 가지 (vmstat, iostat) 정도는 쓸 줄 알아야 한다. 유닉스 계열 OS 명령줄에 툴 명령어를 실행하면 각각 현재 가상 메모리 및 IO 서브시스템 상태에 관한 유용한 데이터를 신속히 제공한다.

`vmstat 1` 은 1초마다 한번씩 찍어 결과를 표시한다.

![스크린샷 2024-01-07 오후 9.40.00.png](./images/스크린샷 2024-01-07 오후 9.40.00.png)

1. proc 섹션 : 실행 가능한(r) 프로세스, 블로킹된(b) 프로세스 개수를 나타낸다.
2. memory 섹션 : 스왑 메모리(swpd), 미사용 메모리(free), 버퍼로 사용한 메모리(buff), 캐시로 사용한 메모리(cache)가 잇따라 표시된다.
3. swap 섹션 : 디스크로 교체되어 들어간 메모리(swap in), 디스크에서 교체되어 빠져나온 메모리(swap out)
4. io 섹션 : 블록인 , 블록아웃 개수는 각각 블록(I/O) 장치에서 받은 512바이트 블록, 블록 장치로 보낸 512바이트 블록 개수다.
5. system 섹션 : 인터럽트(in) 및 초당 컨텍스트 교환(cs) 횟수다.
6. cpu 섹션 : CPU와 직접 연관된 지표를 CPU 사용률(%)로 표기한다. 좌측부터 차례로 유저 시간(us), 커널 시간(sy) , 유휴 시간(id), 대기 시간(wa), 도둑맞은 시간(st)

유저 스레드끼리든, 커널 공간 내부든 컨텍스트 스위칭은 CPU 리소스 낭비를 초래한다. 튜닝이 잘 된 프로그램은 리소스(특히 CPU)를 최대한 활용한다. 계산을 많이 하는 (CPU에 종속된) 워크로드는 유저 공간의 CPU 사용률을 100%에 가깝게 유지하는 것이 목표다. 이것은 사용률이 100%가 되지 않는다면 원인을 찾아야 한다.

대다수(특히 리눅스) OS에서 vmstat는 컨텍스트 교환 발생 횟수를 나타내므로 vmstat 1 명령을 실행하면 컨텍스트 스위칭의 실시간 영향도를 지켜볼 수 있다. 유저 공간에서 CPU사용률이 100%에 못미치는데 어떤 프로세스에서 컨텍스트 교환 비율이 높게 나타나면 I/O 에서 블로킹이 일어났거나 스레드 락 경합(thread lock contention)이 벌어졌을 가능성이 높다.

### 3.6.2 가비지 수집

핫스팟 JVM은 시작 시 메모리 유저 공간에 할당/관리 한다. 그래서 메모리를 할당하느라 시스템콜을 할 필요가 없다. 즉 가비지 수집을 하려고 커널 교환을 할 일이 거의 없다.

따라서 CPU사용률이 아주 높다면 GC는 대부분의 시간을 소비하는 주범이 아니다. GC자체는 유저 공간의 CPU사이클을 소비하되 커널 공간에 사용률에는 영향을 미치지 않는 활동을 한다.

반면, JVM프로세스가 유저 공간에서 CPU를 100%에 가깝게 사용하고 있다면 GC를 의심해야 한다. 성능 분석 시 단순 툴에서 CPU사용률이 100%로 일정하지만 모든 사이클이 유저 공간에서 소비되고 있으면 JVM인탓인지 유저 코드탓인지 의심해봐야 한다.

JVM에서 유저 공간의 CPU사용률이 높은 건 거의 대부분 GC 서브시스템 탓이다. 이럴 땐 GC로그를 확인하고 새 항목이 추가되는 빈도를 알아보자

JVM에서 GC로깅은 거의 무료다. 전체 비용을 최대한 정밀하게 산정해도 주변의 랜덤한 노이즈와 구분하기 어렵다. 분석용 데이터의 원천으로서도 가치가 높으니 JVM 프로세스는 예외없이 로그를 남겨야 한다.

### 3.6.3 입출력

파일 I/O 는 예전부터 전체 시스템 성능에 암적인 존재였다. 엔지니어들이 ‘스피닝 러스트’라고 빈정대는 골치 아픈 물리적 하드웨어와 밀접한 연관이 있기도 하지만 다른 OS파트처럼 분명한 추상화가 되어 있지 않기 때문이다.

예를 들어 메모리는 가상 메모리라는 격리 장치가 있지만, IO는 적절한 추상화 장치가 없다. 자바는 대부분 단순한 IO만 처리하며 IO 서브시스템을 심하게 가동하는 애플리케이션 클래스도 적은 편이다.

호스트당 IO가 집중되는 애플리케이션이 하나만 있는 경우 iostat, vmstat같은 툴로 기본 카운터 기능만 있어도 기초 진단용으로 좋다.

### 커널 바이패스 I/O

커널을 이용해 데이터를 복사해 유저 공간에 넣는 작업이 상당히 비싼 고성능 애플리케이션이 있는데, 커널 대신 직접 네트워크 카드에서 유저가 접근 가능한 영역으로 데이터를 매핑하는 전용 하드웨어/소프트웨어를 쓴다. 이렇게 하면 커널 공간과 유저 공간 사이를 넘나드는 행위 및 이중 복사를 막을 수 있다.

자바는 기본적으로 이와 관련된 구현체를 제공하지 않으므로 필요한 기능을 구현하려면 커스텀(네이티브) 라이브러리를 써야 한다.

![스크린샷 2024-01-08 오후 9.14.49.png](./images/스크린샷 2024-01-08 오후 9.14.49.png)

### 3.6.4 기계 공감

기계 공감은 성능을 조금이라도 쥐어짜내야 하는 상황에서 하드웨어를 폭넓게 이해하고 공간하는 능력이 중요하다고 한다.

기계 공감은 자바 개발자가 무시하기 쉬운 관심사다. JVM이 하드웨어를 추상화했는데 굳이 개발자가 성능 관련 내용을 일일히 파악할 필요가 없을 것이다.  하지만 고성능, 저지연이 필수인 분야에서는 개발자가 자바/JVM을 효과적으로 활용하려면 JVM이란 무엇이고, 하드웨어와는 어떻게 상호작용하는지 이해해야 한다.

예를 들어 프로세스 캐시의 캐시 라인을 쓰면 메모리 블록을 미리 가져올 수 있지만, 멀티스레드 환경에서 두 스레드가 동일한 캐시 라인에 있는 변수를 읽거나 쓰려고 할 때 문제가 된다. 두 스레드가 동일한 캐시 라인을 수정하려고 하면 경합이 발생한다. 한 스레드가 작업을 마치면 다른 스레드는 캐시 라인을 무효화한다. 이런 잘못된 공유(false sharing)은 성능 급락으로 이어진다.

## 3.7 가상화

가상화는 다양한 종류가 있지만 이미 실행 중인 OS위에 OS사본을 하나의 프로세스로 실행시키는 모양새가 보통이다.

![스크린샷 2024-01-08 오후 9.21.01.png](./images/스크린샷 2024-01-08 오후 9.21.01.png)

가상화의 특징이다.

- 가상화 OS에서 실행하는 프로그램은 베어 메탈(비가상화 OS)에서 실행할때와 동일하기 작동해야 한다.
- 하이퍼바이저는 모든 하드웨어 리소스 액세스를 조정해야 한다.
- 가상화 오버헤드는 가급적 작아야 하며 실행 시간의 상당 부분을 차지해선 안된다.

일반 비가상화 시스템에서 OS 커널은 프리빌리지드 모드로 동작하므로 하드웨어를 건드릴 수 있지만, 가상화 시스템에서는 게스트 OS가 하드웨어에 직접 액세스할 수 없다.

대개 프리빌리지드 명령어를 언프리빌리지드 명령어로 수정한다. 또 컨텍스트 교환이 발생하는 동안 지나친 캐시 플러시가 일어나지 않도록 일부 OS 커널의 자료 구조는 섀도해야 한다.

## 3.8 JVM과 운영체제

JVM은 자바 코드에 공용 인터페이스를 제공하여 OS에 독립적인 휴대용 실행 환경을 제공한다. 하지만 스레드 스케줄링같은 아주 기본적인 서비스조차도 하부 OS에 반드시 액세스 해야 한다.

이런 기능은 native 키워드를 붙인 네이티브 메서드로 구현한다. 네이티브 메서드는 C언어로 작성하지만, 여느 자바 메서드처럼 액세스할 수 있다. 이 작업을 대행하는 공통 인터페이스를 **자바 네이티브 인터페이스(Java Native Interface, JNI)**라고 한다.

```java
public Final native Class<?> getClass();
public native int hashCode();
protected native Object clone() throws CloneNotSupportedException;
public Final native void notify();
public Final native void notifyAll();
public Final native void wait(long timeout) throws InterruptedException;
```

이런 네이티브 인터페이스의 메서드들은 C/C++로 작성됐지만 자바에서 C코드 ‘브리지’를 통해 액세스할 수 있다. 핫스팟에서 이 코드들은 어떻게 호출될까?

`System.currentTimeMillis()` 는 `JVM_CurrentTimeMillis()`라는 JVM엔트리 포인트 메서드에 매핑된다.